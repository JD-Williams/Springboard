{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 1: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition: Get source data from NYC Open Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python library for Socrata Open Data API\n",
    "from sodapy import Socrata\n",
    "\n",
    "frames = []\n",
    "batch_size = 1000000\n",
    "\n",
    "# Import dataset via context manager\n",
    "for i in range(9):\n",
    "    with Socrata(\"data.cityofnewyork.us\", None) as client:\n",
    "        results = client.get(\"66ae-7zpy\", limit=batch_size,offset=i*batch_size)\n",
    "    print('Preparing to load Batch {} to dataframe object...'.format(i+1))\n",
    "    temp_df = pd.DataFrame.from_records(results)\n",
    "    print('Batch {} loaded'.format(i+1))\n",
    "    frames.append(temp_df)\n",
    "    print('Dataframe object (df{}) appended to list\\n'.format(i+1))\n",
    "print('\\nAll dataframe objects have been appended to list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing: Define necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to drop immaterial rows and columns from dataframe object\n",
    "def drop_from_df(dfObj):\n",
    "    \"\"\"\n",
    "    Remove columns from dataframe object \n",
    "    that are not required for analysis\n",
    "    \"\"\"\n",
    "    # Drop all rows with missing value for 'incident_disposition_code'\n",
    "    dfObj.dropna(subset=['incident_disposition_code'],inplace=True)\n",
    "    \n",
    "    # Identify all columns that contain incident indicator data\n",
    "    list_of_indicator_cols = [name for name in list(dfObj.columns) \n",
    "                              if 'indicator' in str(name).lower() and name !='held_indicator']\n",
    "    \n",
    "    # Drop all rows that pertain to outlier incidents\n",
    "    for name in list_of_indicator_cols:\n",
    "        index_names = dfObj[dfObj[name]=='Y'].index\n",
    "        dfObj.drop(index_names, inplace=True)\n",
    "    \n",
    "    # Remove columns that contain incident indicator data\n",
    "    dfObj.drop(list_of_indicator_cols,axis=1,inplace=True)\n",
    "    \n",
    "    # Identify and remove all columns that contain district or precinct data (geographic zones)\n",
    "    list_of_zone_cols = [name for name in list(dfObj.columns) \n",
    "                         if ('district' in str(name).lower() or name=='policeprecinct')]\n",
    "    dfObj.drop(list_of_zone_cols,axis=1,inplace=True)\n",
    "    \n",
    "    return dfObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define function to modify dtypes of series in dataframe object\n",
    "def modify_dtype(dfObj):\n",
    "    \"\"\"\n",
    "    Change the dtype of select columns in \n",
    "    dataframe object based on its implied value\n",
    "    \"\"\"\n",
    "    # Create list of all columns that contain ISO8601 datetime\n",
    "    list_of_datetime_cols = [name for name in list(dfObj.columns) \n",
    "                             if 'datetime' in str(name).lower()]\n",
    "\n",
    "    # Convert dtypes for each element in list to datetime\n",
    "    for name in list_of_datetime_cols:\n",
    "        dfObj[name]=pd.to_datetime(dfObj[name])\n",
    "       \n",
    "    # Create list of all columns that contain time duration\n",
    "    list_of_duration_cols = [name for name in list(dfObj.columns) \n",
    "                             if 'seconds' in str(name).lower()]\n",
    "\n",
    "    # Convert dtypes for each element in list to numeric\n",
    "    for name in list_of_duration_cols:\n",
    "        dfObj[name]=pd.to_numeric(dfObj[name])\n",
    "        \n",
    "    # Convert columns to category dtypes to reduce size of dataframe object\n",
    "    dfObj['borough'] = dfObj.borough.astype('category')\n",
    "    dfObj['held_indicator'] = dfObj.held_indicator.astype('category')\n",
    "    dfObj['valid_dispatch_rspns_time_indc'] = dfObj.valid_dispatch_rspns_time_indc.astype('category')\n",
    "    dfObj['valid_incident_rspns_time_indc'] = dfObj.valid_incident_rspns_time_indc.astype('category')\n",
    "    dfObj['incident_dispatch_area'] = dfObj.incident_dispatch_area.astype('category')\n",
    "        \n",
    "    return dfObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redesign_df(dfObj):\n",
    "    \"\"\"\n",
    "    Restructure dataframe object\n",
    "    \"\"\"\n",
    "    # CREATE PANDAS SERIES FOR TARGET VARIABLE: fatality\n",
    "    dfObj['fatality'] = np.logical_or(dfObj.incident_disposition_code == '83',\\\n",
    "                                   dfObj.incident_disposition_code == '96')\n",
    "\n",
    "    # Create separate columns for the year and month of the incident\n",
    "    dfObj['incident_year'] = pd.DatetimeIndex(dfObj.incident_datetime).year\n",
    "    dfObj['incident_month'] = pd.DatetimeIndex(dfObj.incident_datetime).month\n",
    "\n",
    "    # Reorder dataframe columns\n",
    "    col_order = ['incident_year','incident_month','cad_incident_id',\\\n",
    "                 'incident_datetime','borough','zipcode',\\\n",
    "                 'incident_dispatch_area','held_indicator',\\\n",
    "                 'initial_call_type','initial_severity_level_code',\\\n",
    "                 'final_call_type','final_severity_level_code',\\\n",
    "                 'first_assignment_datetime','valid_dispatch_rspns_time_indc',\\\n",
    "                 'dispatch_response_seconds_qy','first_activation_datetime',\\\n",
    "                 'first_on_scene_datetime','valid_incident_rspns_time_indc',\\\n",
    "                 'incident_response_seconds_qy','incident_travel_tm_seconds_qy',\\\n",
    "                 'first_to_hosp_datetime','first_hosp_arrival_datetime',\\\n",
    "                 'incident_close_datetime',\n",
    "                 'incident_disposition_code','fatality']\n",
    "    dfObj=dfObj[col_order]\n",
    "    \n",
    "    # Create a multindex on incident_year and incident_month\n",
    "    dfObj.set_index(['incident_year','incident_month','cad_incident_id'])\n",
    "\n",
    "    return dfObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing: Apply functions to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply drop_from_df to all dataframe objects in frames\n",
    "count = 1\n",
    "for frame in frames:\n",
    "    frame = drop_from_df(frame)\n",
    "    print('Dataframe {}: Removed rows and columns'.format(count))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply modify_dtype to all dataframe objects in frames\n",
    "count = 1\n",
    "for frame in frames:\n",
    "    frame = modify_dtype(frame)\n",
    "    print(\"Dataframe {}: Modified dtypes\".format(count))\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply redesign_df to all dataframe objects in frames\n",
    "count = 1\n",
    "for frame in frames:\n",
    "    frame = redesign_df(frame)\n",
    "    print(\"Dataframe {}: Redesigned df object\".format(count))\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all dataframe objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all dataframe objects\n",
    "df = pd.concat(frames,ignore_index=True)\n",
    "print('Concatenated all dataframe objects in frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multindex on incident_year, incident_month, and cad_incident_id\n",
    "df.set_index(['incident_year','incident_month','cad_incident_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframe to CSV\n",
    "print('Exporting dataframe to CSV...')\n",
    "df.to_csv('data/clean_comp_df.csv',index=False,compression='gzip')\n",
    "print('Dataframe successfully exported to CSV using \\'gzip\\' compression.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
