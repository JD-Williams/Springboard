{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 1: Machine Learning Algorithms - Under-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TOC'></a>\n",
    "<strong>Table of Contents</strong>\n",
    "<ol>\n",
    "    <li>Preliminaries</li>\n",
    "    <ol>\n",
    "        <li><a href=#Sec01A>Import EMS Incident Data</a></li>\n",
    "        <li><a href=#Sec01B>Preprocess Dataset</a></li>\n",
    "        <li><a href=#Sec01C>Segment &amp; Encode Variables</a></li>\n",
    "        <li><a href=#Sec01D>Inspect Target Variables</a></li>\n",
    "    </ol>\n",
    "    <li>Prepare Training Data</li>\n",
    "    <ol>\n",
    "        <li><a href=#Sec02A>Create Train and Test Sets</a></li>\n",
    "        <li><a href=#Sec02B>Instantiate Baseline Classifiers</a></li>\n",
    "    </ol>\n",
    "    <li>Random Under-Sampling (RUS)</li>\n",
    "    <ol>\n",
    "        <li><a href=#Sec03A>Instantiate Training Pipelines</a></li>\n",
    "        <li><a href=#Sec03B>Parameter Tuning - LRCV Pipeline</a></li>\n",
    "        <li><a href=#Sec03C>Parameter Tuning - RF Pipeline</a></li>\n",
    "        <li><a href=#Sec03D>Evaluate Tuned Classifiers</a></li>\n",
    "    </ol>\n",
    "    <li>Near Miss (NM)</li>\n",
    "    <ol>\n",
    "        <li><a href=#Sec04A>Instantiate Training Pipelines</a></li>\n",
    "        <li><a href=#Sec04B>Parameter Tuning - LRCV Pipeline</a></li>\n",
    "        <li><a href=#Sec04C>Parameter Tuning - RF Pipeline</a></li>\n",
    "        <li><a href=#Sec04D>Evaluate Tuned Classifiers</a></li>\n",
    "    </ol>\n",
    "    <li>Tomek's Links (TL)</li>\n",
    "    <ol>\n",
    "        <li><a href=#Sec05A>Instantiate Training Pipelines</a></li>\n",
    "        <li><a href=#Sec05B>Parameter Tuning - LRCV Pipeline</a></li>\n",
    "        <li><a href=#Sec05C>Parameter Tuning - RF Pipeline</a></li>\n",
    "        <li><a href=#Sec05D>Evaluate Tuned Classifiers</a></li>\n",
    "    </ol>\n",
    "    <li>Evaluation of Classifiers</li>\n",
    "    <ol>\n",
    "        <li><a href=#Sec06A>Comparison of Baseline Models</a></li>\n",
    "        <li><a href=#Sec06B>Comparison of Tuned Models</a></li>\n",
    "        <li><a href=#Sec06C>Summary of Analyses</a></li>\n",
    "    </ol>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The goal of this project is to develop machine learning models that predict whether or not the outcome of an EMS incident will result in a fatality. This is a supervised, binary classification problem. Analyses will be performed on a collection of nearly 8 million records of documented incidents, which span the six year period from January 2013 through December 2018, and appropriate predictive models will be developed to achieve the primary objective. This dataset is robust and contains several feature variables, of mixed data types, that describe both various attributes of each incident as well as the responsive action taken by the FDNY. All of the aforementioned factors affect an individual’s survivability once a response is initiated.</p>\n",
    "\n",
    "The results from the <a href=\"https://github.com/jdwill917/SB-DSCT-Repo/blob/master/Capstones/Capstone%201/code/CP1-04a_MLA.ipynb\" target=\"_blank\">baseline MLAs</a> illustrated that the underlying dataset is highly imbalanced on the target variable: `fatality`. This notebook will examine several models generated by combining different under-sampling algorithms and classifiers (parametric and non-parametric). The primary metric that will be used to evaluate each model is <em>recall</em> (the fraction of correctly identified positives within the target variable), but other metrics tailored to imbalanced datasets will also be taken into consideration.\n",
    "\n",
    "<p>The three sampling methods to be explored in this analysis are:</p>\n",
    "<ul>\n",
    "    <li>Random Under-Sampling</li>\n",
    "    <li>NearMiss Sampling</li>\n",
    "    <li>Tomek's Link Sampling</li>\n",
    "</ul>\n",
    "<p>Model scoring will be evaluated for both baseline and tuned classifiers for each method. A similar analysis will be performed for <a href=\"https://github.com/jdwill917/SB-DSCT-Repo/blob/master/Capstones/Capstone%201/code/CP1-04c_MLA.ipynb\" target=\"_blank\">over-sampling methods</a> in a separate notebook.</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-transform: uppercase;\">1. Preliminaries</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Sec01A'></a>\n",
    "<h4>1A: Import EMS incident data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "#sb.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "# Model evaluation tools and metrics\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import (accuracy_score, balanced_accuracy_score,\n",
    "                             precision_score, recall_score, f1_score, auc,\n",
    "                             confusion_matrix, plot_confusion_matrix,\n",
    "                             roc_curve, precision_recall_curve)\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "# Prospective classifiers\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign file path\n",
    "file_path = '../data/clean_EMS_data.csv'\n",
    "\n",
    "# Read CSV data into a Pandas DataFrame\n",
    "datetime_cols = ['incident_datetime',\n",
    "                 'first_assignment_datetime',\n",
    "                 'first_activation_datetime',\n",
    "                 'first_on_scene_datetime',\n",
    "                 'first_to_hosp_datetime',\n",
    "                 'first_hosp_arrival_datetime',\n",
    "                 'incident_close_datetime']\n",
    "\n",
    "df = pd.read_csv(file_path,compression='gzip',\n",
    "                 parse_dates=datetime_cols,\n",
    "                 index_col=['incident_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info(verbose=True,memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec01B\"></a>\n",
    "<h4>1B: Preprocess Dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change dtypes\n",
    "df['borough'] = df.borough.astype('category')\n",
    "df['zipcode'] = df.zipcode.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove immaterial columns\n",
    "list_of_cols = ['latitude','longitude',\n",
    "                'aland_sqmi','awater_sqmi','held_indicator',\n",
    "                'initial_call_type','initial_severity_level',\n",
    "                'first_assignment_datetime','incident_dispatch_area',\n",
    "                'dispatch_time','travel_time',\n",
    "                'first_activation_datetime','first_on_scene_datetime',\n",
    "                'first_to_hosp_datetime','first_hosp_arrival_datetime',\n",
    "                'incident_close_datetime','incident_disposition_code']\n",
    "df.drop(list_of_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info(verbose=True,memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>borough</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>final_call_type</th>\n",
       "      <th>final_severity_level</th>\n",
       "      <th>response_time</th>\n",
       "      <th>life_threatening</th>\n",
       "      <th>fatality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2013-01-01 00:00:04</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10472.0</td>\n",
       "      <td>RESPIR</td>\n",
       "      <td>4</td>\n",
       "      <td>797.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-01 00:05:52</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10472.0</td>\n",
       "      <td>EDP</td>\n",
       "      <td>7</td>\n",
       "      <td>534.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-01 00:20:37</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10472.0</td>\n",
       "      <td>SICK</td>\n",
       "      <td>6</td>\n",
       "      <td>697.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-01 01:53:11</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10472.0</td>\n",
       "      <td>INJURY</td>\n",
       "      <td>4</td>\n",
       "      <td>223.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-01 01:54:28</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10472.0</td>\n",
       "      <td>SICK</td>\n",
       "      <td>4</td>\n",
       "      <td>298.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     year  month  day  hour  weekday borough  zipcode  \\\n",
       "incident_datetime                                                       \n",
       "2013-01-01 00:00:04  2013      1    1     0        2   BRONX  10472.0   \n",
       "2013-01-01 00:05:52  2013      1    1     0        2   BRONX  10472.0   \n",
       "2013-01-01 00:20:37  2013      1    1     0        2   BRONX  10472.0   \n",
       "2013-01-01 01:53:11  2013      1    1     1        2   BRONX  10472.0   \n",
       "2013-01-01 01:54:28  2013      1    1     1        2   BRONX  10472.0   \n",
       "\n",
       "                    final_call_type  final_severity_level  response_time  \\\n",
       "incident_datetime                                                          \n",
       "2013-01-01 00:00:04          RESPIR                     4          797.0   \n",
       "2013-01-01 00:05:52             EDP                     7          534.0   \n",
       "2013-01-01 00:20:37            SICK                     6          697.0   \n",
       "2013-01-01 01:53:11          INJURY                     4          223.0   \n",
       "2013-01-01 01:54:28            SICK                     4          298.0   \n",
       "\n",
       "                     life_threatening  fatality  \n",
       "incident_datetime                                \n",
       "2013-01-01 00:00:04             False     False  \n",
       "2013-01-01 00:05:52             False     False  \n",
       "2013-01-01 00:20:37             False     False  \n",
       "2013-01-01 01:53:11             False     False  \n",
       "2013-01-01 01:54:28             False     False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec01C\"></a>\n",
    "<h4>1C: Segment &amp; Encode Feature Variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7988028, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>borough_0</th>\n",
       "      <th>borough_1</th>\n",
       "      <th>borough_2</th>\n",
       "      <th>borough_3</th>\n",
       "      <th>zipcode_0</th>\n",
       "      <th>...</th>\n",
       "      <th>final_call_type_3</th>\n",
       "      <th>final_call_type_4</th>\n",
       "      <th>final_call_type_5</th>\n",
       "      <th>final_call_type_6</th>\n",
       "      <th>final_call_type_7</th>\n",
       "      <th>final_call_type_8</th>\n",
       "      <th>final_severity_level</th>\n",
       "      <th>response_time</th>\n",
       "      <th>life_threatening</th>\n",
       "      <th>fatality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2013-01-01 00:00:04</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>797.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-01 00:05:52</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>534.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-01 00:20:37</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>697.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-01 01:53:11</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>223.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-01 01:54:28</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>298.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     year  month  day  hour  weekday  borough_0  borough_1  \\\n",
       "incident_datetime                                                            \n",
       "2013-01-01 00:00:04  2013      1    1     0        2          0          0   \n",
       "2013-01-01 00:05:52  2013      1    1     0        2          0          0   \n",
       "2013-01-01 00:20:37  2013      1    1     0        2          0          0   \n",
       "2013-01-01 01:53:11  2013      1    1     1        2          0          0   \n",
       "2013-01-01 01:54:28  2013      1    1     1        2          0          0   \n",
       "\n",
       "                     borough_2  borough_3  zipcode_0  ...  final_call_type_3  \\\n",
       "incident_datetime                                     ...                      \n",
       "2013-01-01 00:00:04          0          1          0  ...                  0   \n",
       "2013-01-01 00:05:52          0          1          0  ...                  0   \n",
       "2013-01-01 00:20:37          0          1          0  ...                  0   \n",
       "2013-01-01 01:53:11          0          1          0  ...                  0   \n",
       "2013-01-01 01:54:28          0          1          0  ...                  0   \n",
       "\n",
       "                     final_call_type_4  final_call_type_5  final_call_type_6  \\\n",
       "incident_datetime                                                              \n",
       "2013-01-01 00:00:04                  0                  0                  0   \n",
       "2013-01-01 00:05:52                  0                  0                  0   \n",
       "2013-01-01 00:20:37                  0                  0                  0   \n",
       "2013-01-01 01:53:11                  0                  0                  1   \n",
       "2013-01-01 01:54:28                  0                  0                  0   \n",
       "\n",
       "                     final_call_type_7  final_call_type_8  \\\n",
       "incident_datetime                                           \n",
       "2013-01-01 00:00:04                  0                  1   \n",
       "2013-01-01 00:05:52                  1                  0   \n",
       "2013-01-01 00:20:37                  1                  1   \n",
       "2013-01-01 01:53:11                  0                  0   \n",
       "2013-01-01 01:54:28                  1                  1   \n",
       "\n",
       "                     final_severity_level  response_time  life_threatening  \\\n",
       "incident_datetime                                                            \n",
       "2013-01-01 00:00:04                     4          797.0             False   \n",
       "2013-01-01 00:05:52                     7          534.0             False   \n",
       "2013-01-01 00:20:37                     6          697.0             False   \n",
       "2013-01-01 01:53:11                     4          223.0             False   \n",
       "2013-01-01 01:54:28                     4          298.0             False   \n",
       "\n",
       "                     fatality  \n",
       "incident_datetime              \n",
       "2013-01-01 00:00:04     False  \n",
       "2013-01-01 00:05:52     False  \n",
       "2013-01-01 00:20:37     False  \n",
       "2013-01-01 01:53:11     False  \n",
       "2013-01-01 01:54:28     False  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nominal feature variables\n",
    "var_names_nom = ['borough','zipcode','final_call_type']\n",
    "vars_nom = df[var_names_nom]\n",
    "\n",
    "# Binary encode dataframe\n",
    "enc_binary = ce.BinaryEncoder(cols=var_names_nom)\n",
    "df_bin = enc_binary.fit_transform(df)\n",
    "\n",
    "# Inspect encoded dataframe\n",
    "print(df_bin.shape)\n",
    "df_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "Type:  <class 'numpy.ndarray'>\n",
      "Shape: (7988028,)\n",
      "\n",
      "X (Binary-Encoded)\n",
      "Type:  <class 'numpy.ndarray'>\n",
      "Shape: (7988028, 30)\n"
     ]
    }
   ],
   "source": [
    "# Target variable\n",
    "y_bin = df_bin['fatality'].values\n",
    "print(f\"y\\nType:  {type(y_bin)}\\nShape: {y_bin.shape}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# All feature variables\n",
    "X_bin = df_bin.iloc[:,:-1].values\n",
    "print(f\"X (Binary-Encoded)\\nType:  {type(X_bin)}\\nShape: {X_bin.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Applying binary encoding increases the number of feature variables in the clean dataset from 11 to 30. <a href=#TOC>TOC</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec01D\"></a>\n",
    "<h4>1D: Inspect Target Variable</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatalities:  338684 ( 4.24%)\n",
      "Survivals:  7649344 (95.76%)\n"
     ]
    }
   ],
   "source": [
    "# Subsets for two classes of target\n",
    "fatalities = df_bin[df_bin.fatality == True] # positives\n",
    "survivals = df_bin[df_bin.fatality == False] # negatives\n",
    "\n",
    "# Calculate frequency and proportion of classes\n",
    "n_pos = len(fatalities.fatality)\n",
    "n_neg = len(survivals.fatality)\n",
    "pct_pos = (n_pos/len(df_bin['fatality'])) * 100\n",
    "pct_neg = (n_neg/len(df_bin['fatality'])) * 100\n",
    "\n",
    "# Output results\n",
    "print(\"Fatalities: {0:7} ({1:5.4}%)\".format(n_pos,pct_pos))\n",
    "print(\"Survivals:  {0:7} ({1:5.4}%)\".format(n_neg,pct_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is segmented into two <em>imbalanced</em> classes: <strong>fatalities</strong> (`fatality == True`) and <strong>survivals</strong> (`fatality == False`). Based on the frequency values provided above, <strong>fatalities</strong> represent the <em>minority</em> class (4.24%) whereas <strong>survivals</strong> represent the <em>majority</em> class (95.76%). Various sampling techniques will be utilized in the sections to follow in order to develop effective models for analyses. <a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-transform: uppercase;\">2. Prepare Training Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec02A\"></a>\n",
    "<h4>2A: Create Train and Test Sets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "RANDOM_STATE = 917\n",
    "TEST_SIZE = 0.20\n",
    "\n",
    "# Split and stratify the binary-encoded data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bin, y_bin, stratify=y_bin,\n",
    "                                                    test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA = 6390422 observations\n",
      "Class Counts: {'Fatalities': 270947, 'Survivals': 6119475}\n",
      "Proportions:  {'Fatalities': 0.0424, 'Survivals': 0.9576}\n",
      "\n",
      "TEST DATA     = 1597606 observations\n",
      "Class Counts: {'Fatalities': 67737, 'Survivals': 1529869}\n",
      "Proportions:  {'Fatalities': 0.0424, 'Survivals': 0.9576}\n"
     ]
    }
   ],
   "source": [
    "# Define function to calculate target class counts\n",
    "def get_class_counts(arr):\n",
    "    class_f = sum(arr)\n",
    "    class_s = len(arr) - class_f\n",
    "    return {'Fatalities': class_f, 'Survivals':class_s}\n",
    "\n",
    "# Define function to calculate target class proportions\n",
    "def get_class_proportions(arr):\n",
    "    class_f = round(sum(arr)/len(arr),4)\n",
    "    class_s = 1 - class_f\n",
    "    return {'Fatalities': class_f, 'Survivals':class_s}\n",
    "\n",
    "# Output results\n",
    "print(f\"TRAINING DATA = {len(y_train)} observations\")\n",
    "print(f\"Class Counts: {get_class_counts(y_train)}\")\n",
    "print(f\"Proportions:  {get_class_proportions(y_train)}\")\n",
    "print()\n",
    "print(f\"TEST DATA     = {len(y_test)} observations\")\n",
    "print(f\"Class Counts: {get_class_counts(y_test)}\")\n",
    "print(f\"Proportions:  {get_class_proportions(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Stratification is necessary to lock the distribution of classes in the train and test sets given the high imbalance within the target classes of the original data set. <a href=#TOC>TOC</a><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec02B\"></a>\n",
    "<h4>2B: Instantiate Baseline Classifiers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5221381075292209, 1: 11.792744859515064}\n"
     ]
    }
   ],
   "source": [
    "# Compute target class weights\n",
    "classes = np.unique(y_bin)\n",
    "cw = compute_class_weight('balanced',classes,y_bin)\n",
    "cw_dict = {0:cw[0],1:cw[1]}\n",
    "\n",
    "# Output results\n",
    "print(f\"Class Weights: {cw_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lrcv = LogisticRegressionCV(random_state=RANDOM_STATE,\n",
    "                                class_weight=cw_dict,max_iter=10000,scoring='recall_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=RANDOM_STATE,\n",
    "                                class_weight=cw_dict,warm_start=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This analysis will compare the usage of a parametric classifier (LogisticRegressionCV) and a non-parametric classifier (RandomForest), and their respective impacts on the selected model scoring metrics. <a href=#TOC>TOC</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-transform: uppercase;\">3. Random Under-Sampling (RUS)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec03A\"></a>\n",
    "<h4>3A: Instantiate Training Pipelines</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pipeline for sampling method and LogisticRegressionCV (LRCV)\n",
    "clf_rus_lrcv = make_pipeline(RandomUnderSampler(random_state=RANDOM_STATE),clf_lrcv)\n",
    "\n",
    "# Make pipeline for sampling method and Random Forest (RF)\n",
    "clf_rus_rf = make_pipeline(RandomUnderSampler(random_state=RANDOM_STATE),clf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregressioncv': LogisticRegressionCV(Cs=10,\n",
      "                     class_weight={0: 0.5221381075292209,\n",
      "                                   1: 11.792744859515064},\n",
      "                     cv=None, dual=False, fit_intercept=True,\n",
      "                     intercept_scaling=1.0, l1_ratios=None, max_iter=10000,\n",
      "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                     random_state=917, refit=True, scoring='recall_weighted',\n",
      "                     solver='lbfgs', tol=0.0001, verbose=0),\n",
      " 'logisticregressioncv__Cs': 10,\n",
      " 'logisticregressioncv__class_weight': {0: 0.5221381075292209,\n",
      "                                        1: 11.792744859515064},\n",
      " 'logisticregressioncv__cv': None,\n",
      " 'logisticregressioncv__dual': False,\n",
      " 'logisticregressioncv__fit_intercept': True,\n",
      " 'logisticregressioncv__intercept_scaling': 1.0,\n",
      " 'logisticregressioncv__l1_ratios': None,\n",
      " 'logisticregressioncv__max_iter': 10000,\n",
      " 'logisticregressioncv__multi_class': 'auto',\n",
      " 'logisticregressioncv__n_jobs': None,\n",
      " 'logisticregressioncv__penalty': 'l2',\n",
      " 'logisticregressioncv__random_state': 917,\n",
      " 'logisticregressioncv__refit': True,\n",
      " 'logisticregressioncv__scoring': 'recall_weighted',\n",
      " 'logisticregressioncv__solver': 'lbfgs',\n",
      " 'logisticregressioncv__tol': 0.0001,\n",
      " 'logisticregressioncv__verbose': 0,\n",
      " 'memory': None,\n",
      " 'randomundersampler': RandomUnderSampler(random_state=917, replacement=False,\n",
      "                   sampling_strategy='auto'),\n",
      " 'randomundersampler__random_state': 917,\n",
      " 'randomundersampler__replacement': False,\n",
      " 'randomundersampler__sampling_strategy': 'auto',\n",
      " 'steps': [('randomundersampler',\n",
      "            RandomUnderSampler(random_state=917, replacement=False,\n",
      "                   sampling_strategy='auto')),\n",
      "           ('logisticregressioncv',\n",
      "            LogisticRegressionCV(Cs=10,\n",
      "                     class_weight={0: 0.5221381075292209,\n",
      "                                   1: 11.792744859515064},\n",
      "                     cv=None, dual=False, fit_intercept=True,\n",
      "                     intercept_scaling=1.0, l1_ratios=None, max_iter=10000,\n",
      "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                     random_state=917, refit=True, scoring='recall_weighted',\n",
      "                     solver='lbfgs', tol=0.0001, verbose=0))],\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# Get parameters for LRCV pipeline\n",
    "pprint(clf_rus_lrcv.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None,\n",
      " 'randomforestclassifier': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                       class_weight={0: 0.5221381075292209,\n",
      "                                     1: 11.792744859515064},\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=917,\n",
      "                       verbose=0, warm_start=True),\n",
      " 'randomforestclassifier__bootstrap': True,\n",
      " 'randomforestclassifier__ccp_alpha': 0.0,\n",
      " 'randomforestclassifier__class_weight': {0: 0.5221381075292209,\n",
      "                                          1: 11.792744859515064},\n",
      " 'randomforestclassifier__criterion': 'gini',\n",
      " 'randomforestclassifier__max_depth': None,\n",
      " 'randomforestclassifier__max_features': 'auto',\n",
      " 'randomforestclassifier__max_leaf_nodes': None,\n",
      " 'randomforestclassifier__max_samples': None,\n",
      " 'randomforestclassifier__min_impurity_decrease': 0.0,\n",
      " 'randomforestclassifier__min_impurity_split': None,\n",
      " 'randomforestclassifier__min_samples_leaf': 1,\n",
      " 'randomforestclassifier__min_samples_split': 2,\n",
      " 'randomforestclassifier__min_weight_fraction_leaf': 0.0,\n",
      " 'randomforestclassifier__n_estimators': 100,\n",
      " 'randomforestclassifier__n_jobs': None,\n",
      " 'randomforestclassifier__oob_score': False,\n",
      " 'randomforestclassifier__random_state': 917,\n",
      " 'randomforestclassifier__verbose': 0,\n",
      " 'randomforestclassifier__warm_start': True,\n",
      " 'randomundersampler': RandomUnderSampler(random_state=917, replacement=False,\n",
      "                   sampling_strategy='auto'),\n",
      " 'randomundersampler__random_state': 917,\n",
      " 'randomundersampler__replacement': False,\n",
      " 'randomundersampler__sampling_strategy': 'auto',\n",
      " 'steps': [('randomundersampler',\n",
      "            RandomUnderSampler(random_state=917, replacement=False,\n",
      "                   sampling_strategy='auto')),\n",
      "           ('randomforestclassifier',\n",
      "            RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                       class_weight={0: 0.5221381075292209,\n",
      "                                     1: 11.792744859515064},\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=917,\n",
      "                       verbose=0, warm_start=True))],\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# Get parameters for RF pipeline\n",
    "pprint(clf_rus_rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec03B\"></a>\n",
    "<h4>3B: Parameter Tuning - LRCV Pipeline</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter ranges for LRCV pipeline\n",
    "params_rus_lrcv ={\n",
    "    'randomundersampler__replacement': [False,True],\n",
    "    'logisticregressioncv__Cs': [1,10],\n",
    "    'logisticregressioncv__cv': [3,5],\n",
    "    'logisticregressioncv__solver': ['lbfgs','sag']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['balanced_accuracy','recall_weighted']\n",
    "\n",
    "# Instantiate randomized search across finite combinations\n",
    "rnd_rus_lrcv = RandomizedSearchCV(estimator = clf_rus_lrcv, \n",
    "                                  param_distributions = params_rus_lrcv, \n",
    "                                  n_iter = 4,\n",
    "                                  scoring=scores,\n",
    "                                  refit='recall_weighted',\n",
    "                                  error_score=0,\n",
    "                                  random_state = RANDOM_STATE)\n",
    "\n",
    "# Instantiate exhaustive search across all combinations\n",
    "grd_rus_lrcv = GridSearchCV(estimator = clf_rus_lrcv, \n",
    "                            param_grid = params_rus_lrcv,\n",
    "                            scoring=scores,\n",
    "                            refit='recall_weighted',\n",
    "                            error_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit base pipeline\n",
    "clf_rus_lrcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "rnd_rus_lrcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit the grid search model\n",
    "grd_rus_lrcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec03C\"></a>\n",
    "<h4>3C: Parameter Tuning - RF Pipeline</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter ranges for RF\n",
    "params_rus_rf ={\n",
    "    'randomundersampler__replacement': [False,True],\n",
    "    'randomforestclassifier__bootstrap': [False,True],\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt'],\n",
    "    'randomforestclassifier__n_estimators': [50,100,150],\n",
    "    'randomforestclassifier__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'randomforestclassifier__min_samples_leaf': [1, 2, 4],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['balanced_accuracy','recall_weighted']\n",
    "\n",
    "# Instantiate randomized search across combinations\n",
    "rnd_rus_rf = RandomizedSearchCV(estimator = clf_rus_rf, \n",
    "                                param_distributions = params_rus_rf, \n",
    "                                n_iter = 20,\n",
    "                                scoring=scores,\n",
    "                                refit='recall_weighted',\n",
    "                                error_score=0,\n",
    "                                random_state = RANDOM_STATE)\n",
    "\n",
    "# Instantiate exhaustive search across all combinations\n",
    "grd_rus_rf = GridSearchCV(estimator = clf_rus_rf, \n",
    "                          param_grid = params_rus_rf,\n",
    "                          scoring=scores,\n",
    "                          refit='recall_weighted',\n",
    "                          error_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit base pipeline\n",
    "clf_rus_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "rnd_rus_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search model\n",
    "grd_rus_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec03D\"></a>\n",
    "<h4>3D: Evaluate Tuned Classifiers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregressioncv__cv': 5}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best parameters for LRCV pipeline\n",
    "grd_rus_lrcv.best_params_\n",
    "\n",
    "# Get best parameters for RF pipeline\n",
    "grd_rus_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tuned classifiers\n",
    "tuned_rus_lrcv = make_pipeline(RandomUnderSampler(random_state=RANDOM_STATE),\n",
    "                               LogisticRegressionCV(random_state=RANDOM_STATE,cv=5,\n",
    "                                                    class_weight=cw_dict,\n",
    "                                                    max_iter=10000,\n",
    "                                                    scoring='recall_weighted'))\n",
    "\n",
    "tuned_rus_rf = make_pipeline(RandomUnderSampler(random_state=RANDOM_STATE),\n",
    "                             RandomForestClassifier(random_state=RANDOM_STATE,\n",
    "                                                    class_weight=cw_dict,warm_start=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('randomundersampler',\n",
       "                 RandomUnderSampler(random_state=917, replacement=False,\n",
       "                                    sampling_strategy='auto')),\n",
       "                ('logisticregressioncv',\n",
       "                 LogisticRegressionCV(Cs=10, class_weight='balanced', cv=5,\n",
       "                                      dual=False, fit_intercept=True,\n",
       "                                      intercept_scaling=1.0, l1_ratios=None,\n",
       "                                      max_iter=10000, multi_class='auto',\n",
       "                                      n_jobs=None, penalty='l2',\n",
       "                                      random_state=917, refit=True,\n",
       "                                      scoring='recall_weighted', solver='lbfgs',\n",
       "                                      tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit tuned models\n",
    "tuned_rus_lrcv.fit(X_train,y_train)\n",
    "tuned_rus_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction with the classifier\n",
    "ypred_test_rus_lrcv = tuned_rus_lrcv.predict(X_test)\n",
    "\n",
    "# Predict class probabilities and obtain scores\n",
    "probs_rus_lrcv = tuned_rus_lrcv.predict_proba(X_test)\n",
    "probs_rus_lrcv = probs_rus_lrcv[:, 1]\n",
    "precision_rus_lrcv, recall_rus_lrcv, _ = precision_recall_curve(y_test, probs_rus_lrcv)\n",
    "f1_rus_lrcv, auc_rus_lrcv = f1_score(y_test, ypred_test_rus_lrcv), auc(recall_rus_lrcv, precision_rus_lrcv)\n",
    "\n",
    "# Make prediction with the classifier\n",
    "ypred_test_rus_rf = tuned_rus_rf.predict(X_test)\n",
    "\n",
    "# Predict class probabilities and obtain scores\n",
    "probs_rus_rf = clf_rus_rf.predict_proba(X_test)\n",
    "probs_rus_rf = probs_rus_rf[:, 1]\n",
    "precision_rus_rf, recall_rus_rf, _ = precision_recall_curve(y_test, probs_rus_rf)\n",
    "f1_rus_rf, auc_rus_rf = f1_score(y_test, ypred_test_rus_rf), auc(recall_rus_rf, precision_rus_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFIER: LOGISTIC REGRESSION w/ Random Under-Sampling\n",
      "\n",
      "Accuracy score:          0.6486 (y_test, ypred_test_rus_lrcv)\n",
      "Balanced accuracy score: 0.6658 (y_test, ypred_test_rus_lrcv)\n",
      "Recall score:            0.6845 (y_test, ypred_test_rus_lrcv)\n",
      "F1 score:                0.1418 (y_test, ypred_test_rus_lrcv)\n",
      "AUC score:               0.0942 (recall_rus_lrcv, precision_rus_lrcv)\n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "      False       0.98      0.65      0.68      0.78      0.67      0.44   1912336\n",
      "       True       0.08      0.68      0.65      0.14      0.67      0.44     84671\n",
      "\n",
      "avg / total       0.94      0.65      0.68      0.75      0.67      0.44   1997007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics for Logistic Regression classifier\n",
    "print('CLASSIFIER: LOGISTIC REGRESSION w/ Random Under-Sampling')\n",
    "print()\n",
    "\n",
    "# Compute and print key scores\n",
    "print(f\"Accuracy score:          {accuracy_score(y_test, ypred_test_rus_lrcv):.4f} (y_test, ypred_test)\")\n",
    "print(f\"Balanced accuracy score: {balanced_accuracy_score(y_test, ypred_test_rus_lrcv):.4f} (y_test, ypred_test)\")\n",
    "print(f\"Recall score:            {recall_score(y_test, ypred_test_rus_lrcv):.4f} (y_test, ypred_test)\")\n",
    "print(f\"F1 score:                {f1_rus_lrcv:.4f} (y_test, ypred_test)\")\n",
    "print(f\"AUC score:               {auc_rus_lrcv:.4f} (recall, precision)\")\n",
    "print()\n",
    "\n",
    "# Show the classification report\n",
    "print(classification_report_imbalanced(y_test, ypred_test_rus_lrcv))\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Evaluation metrics for Random Forest classifier\n",
    "print('CLASSIFIER: RANDOM FOREST w/ Random Under-Sampling')\n",
    "print()\n",
    "\n",
    "# Compute and print key scores\n",
    "print(f\"Accuracy score:          {accuracy_score(y_test, ypred_test_rus_rf):.4f} (y_test, ypred_test)\")\n",
    "print(f\"Balanced accuracy score: {balanced_accuracy_score(y_test, ypred_test_rus_rf):.4f} (y_test, ypred_test)\")\n",
    "print(f\"Recall score:            {recall_score(y_test, ypred_test_rus_rf):.4f} (y_test, ypred_test)\")\n",
    "print(f\"F1 score:                {f1_rus_rf:.4f} (y_test, ypred_test)\")\n",
    "print(f\"AUC score:               {auc_rus_rf:.4f} (recall, precision)\")\n",
    "\n",
    "# Show the classification report\n",
    "print(classification_report_imbalanced(y_test, ypred_test_rus_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix plot for test data\n",
    "y_class_names = ['Survivals','Fatalities']\n",
    "fig3D1, (ax3D1a,ax3D1b) = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "# Logistic Regression\n",
    "disp = plot_confusion_matrix(clf_rus_lr,X_test,y_test,normalize='all',\n",
    "                             ax=ax3D1a,display_labels=y_class_names,cmap='Reds')\n",
    "ax3D1a.set_title('Test Data: Logistic Regression\\nRandom Under-Sampling',size=16)\n",
    "ax3D1a.set_xlabel('Predicted Label',size=14)\n",
    "ax3D1a.set_ylabel('True Label',size=14)\n",
    "\n",
    "# Random Forest\n",
    "disp = plot_confusion_matrix(clf_rus_rf,X_test,y_test,normalize='all',\n",
    "                             ax=ax3D1b,display_labels=y_class_names,cmap='Reds')\n",
    "ax3D1b.set_title('Test Data: Random Forest\\nRandom Under-Sampling',size=16)\n",
    "ax3D1b.set_xlabel('Predicted Label',size=14)\n",
    "ax3D1b.set_ylabel('True Label',size=14)\n",
    "\n",
    "#plt.savefig('../graphics/CP1-04b_fig03D1.png') # Export confusion matrix plot to PNG file\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the precision-recall curves\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "fig3D2, (ax3D2a,ax3D2b) = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "# Logistic Regression\n",
    "ax3D2a.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "ax3D2a.plot(recall_rus_lr, precision_rus_lr, marker='.', label='Logistic')\n",
    "ax3D2a.set_title('Precision-Recall Curve: Logistic Regression\\nRandom Under-Sampling',size=16)\n",
    "ax3D2a.set_xlabel('Recall',size=14)\n",
    "ax3D2a.set_ylabel('Precision',size=14)\n",
    "ax3D2a.legend()\n",
    "\n",
    "# Random Forest\n",
    "ax3D2b.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "ax3D2b.plot(recall_rus_rf, precision_rus_rf, marker='.', label='Random Forest')\n",
    "ax3D2b.set_title('Precision-Recall Curve: Random Forest\\nRandom Under-Sampling',size=16)\n",
    "ax3D2b.set_xlabel('Recall',size=14)\n",
    "ax3D2b.set_ylabel('Precision',size=14)\n",
    "ax3D2b.legend()\n",
    "\n",
    "#plt.savefig('../graphics/CP1-04b_fig03D2.png') # Export precision-recall curves to PNG file\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-transform: uppercase;\">4. Near Miss (NM)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec04A\"></a>\n",
    "<h4>4A: Instantiate Training Pipelinest</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pipeline for sampling method and LogisticRegressionCV (LRCV)\n",
    "clf_nm_lrcv = make_pipeline(NearMiss(),clf_lrcv)\n",
    "\n",
    "# Make pipeline for sampling method and Random Forest (RF)\n",
    "clf_nm_rf = make_pipeline(NearMiss(),clf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregressioncv': LogisticRegressionCV(Cs=10,\n",
      "                     class_weight={0: 0.5221381075292209,\n",
      "                                   1: 11.792744859515064},\n",
      "                     cv=None, dual=False, fit_intercept=True,\n",
      "                     intercept_scaling=1.0, l1_ratios=None, max_iter=10000,\n",
      "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                     random_state=917, refit=True, scoring='recall_weighted',\n",
      "                     solver='lbfgs', tol=0.0001, verbose=0),\n",
      " 'logisticregressioncv__Cs': 10,\n",
      " 'logisticregressioncv__class_weight': {0: 0.5221381075292209,\n",
      "                                        1: 11.792744859515064},\n",
      " 'logisticregressioncv__cv': None,\n",
      " 'logisticregressioncv__dual': False,\n",
      " 'logisticregressioncv__fit_intercept': True,\n",
      " 'logisticregressioncv__intercept_scaling': 1.0,\n",
      " 'logisticregressioncv__l1_ratios': None,\n",
      " 'logisticregressioncv__max_iter': 10000,\n",
      " 'logisticregressioncv__multi_class': 'auto',\n",
      " 'logisticregressioncv__n_jobs': None,\n",
      " 'logisticregressioncv__penalty': 'l2',\n",
      " 'logisticregressioncv__random_state': 917,\n",
      " 'logisticregressioncv__refit': True,\n",
      " 'logisticregressioncv__scoring': 'recall_weighted',\n",
      " 'logisticregressioncv__solver': 'lbfgs',\n",
      " 'logisticregressioncv__tol': 0.0001,\n",
      " 'logisticregressioncv__verbose': 0,\n",
      " 'memory': None,\n",
      " 'nearmiss': NearMiss(n_jobs=None, n_neighbors=3, n_neighbors_ver3=3,\n",
      "         sampling_strategy='auto', version=1),\n",
      " 'nearmiss__n_jobs': None,\n",
      " 'nearmiss__n_neighbors': 3,\n",
      " 'nearmiss__n_neighbors_ver3': 3,\n",
      " 'nearmiss__sampling_strategy': 'auto',\n",
      " 'nearmiss__version': 1,\n",
      " 'steps': [('nearmiss',\n",
      "            NearMiss(n_jobs=None, n_neighbors=3, n_neighbors_ver3=3,\n",
      "         sampling_strategy='auto', version=1)),\n",
      "           ('logisticregressioncv',\n",
      "            LogisticRegressionCV(Cs=10,\n",
      "                     class_weight={0: 0.5221381075292209,\n",
      "                                   1: 11.792744859515064},\n",
      "                     cv=None, dual=False, fit_intercept=True,\n",
      "                     intercept_scaling=1.0, l1_ratios=None, max_iter=10000,\n",
      "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                     random_state=917, refit=True, scoring='recall_weighted',\n",
      "                     solver='lbfgs', tol=0.0001, verbose=0))],\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# Get parameters for LRCV pipeline\n",
    "pprint(clf_nm_lrcv.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None,\n",
      " 'nearmiss': NearMiss(n_jobs=None, n_neighbors=3, n_neighbors_ver3=3,\n",
      "         sampling_strategy='auto', version=1),\n",
      " 'nearmiss__n_jobs': None,\n",
      " 'nearmiss__n_neighbors': 3,\n",
      " 'nearmiss__n_neighbors_ver3': 3,\n",
      " 'nearmiss__sampling_strategy': 'auto',\n",
      " 'nearmiss__version': 1,\n",
      " 'randomforestclassifier': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                       class_weight={0: 0.5221381075292209,\n",
      "                                     1: 11.792744859515064},\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=917,\n",
      "                       verbose=0, warm_start=True),\n",
      " 'randomforestclassifier__bootstrap': True,\n",
      " 'randomforestclassifier__ccp_alpha': 0.0,\n",
      " 'randomforestclassifier__class_weight': {0: 0.5221381075292209,\n",
      "                                          1: 11.792744859515064},\n",
      " 'randomforestclassifier__criterion': 'gini',\n",
      " 'randomforestclassifier__max_depth': None,\n",
      " 'randomforestclassifier__max_features': 'auto',\n",
      " 'randomforestclassifier__max_leaf_nodes': None,\n",
      " 'randomforestclassifier__max_samples': None,\n",
      " 'randomforestclassifier__min_impurity_decrease': 0.0,\n",
      " 'randomforestclassifier__min_impurity_split': None,\n",
      " 'randomforestclassifier__min_samples_leaf': 1,\n",
      " 'randomforestclassifier__min_samples_split': 2,\n",
      " 'randomforestclassifier__min_weight_fraction_leaf': 0.0,\n",
      " 'randomforestclassifier__n_estimators': 100,\n",
      " 'randomforestclassifier__n_jobs': None,\n",
      " 'randomforestclassifier__oob_score': False,\n",
      " 'randomforestclassifier__random_state': 917,\n",
      " 'randomforestclassifier__verbose': 0,\n",
      " 'randomforestclassifier__warm_start': True,\n",
      " 'steps': [('nearmiss',\n",
      "            NearMiss(n_jobs=None, n_neighbors=3, n_neighbors_ver3=3,\n",
      "         sampling_strategy='auto', version=1)),\n",
      "           ('randomforestclassifier',\n",
      "            RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                       class_weight={0: 0.5221381075292209,\n",
      "                                     1: 11.792744859515064},\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=917,\n",
      "                       verbose=0, warm_start=True))],\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# Get parameters for RF pipeline\n",
    "pprint(clf_nm_rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec04B\"></a>\n",
    "<h4>4B: Parameter Tuning - LRCV Pipeline</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter ranges for LRCV pipeline\n",
    "params_nm_lrcv ={\n",
    "    'nearmiss__version': [1,2,3],\n",
    "    'logisticregressioncv__Cs': [1,10],\n",
    "    'logisticregressioncv__cv': [3,5],\n",
    "    'logisticregressioncv__solver': ['lbfgs','sag']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['balanced_accuracy','recall_weighted']\n",
    "\n",
    "# Instantiate randomized search across finite combinations\n",
    "rnd_nm_lrcv = RandomizedSearchCV(estimator = clf_nm_lrcv, \n",
    "                                  param_distributions = params_nm_lrcv, \n",
    "                                  n_iter = 4,\n",
    "                                  scoring=scores,\n",
    "                                  refit='recall_weighted',\n",
    "                                  error_score=0,\n",
    "                                  random_state = RANDOM_STATE)\n",
    "\n",
    "# Instantiate exhaustive search across all combinations\n",
    "grd_nm_lrcv = GridSearchCV(estimator = clf_nm_lrcv, \n",
    "                            param_grid = params_nm_lrcv,\n",
    "                            scoring=scores,\n",
    "                            refit='recall_weighted',\n",
    "                            error_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit base pipeline\n",
    "clf_nm_lrcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "rnd_nm_lrcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit the grid search model\n",
    "grd_nm_lrcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec04C\"></a>\n",
    "<h4>4C: Parameter Tuning - RF Pipeline</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter ranges for RF\n",
    "params_nm_rf ={\n",
    "    'nearmiss__version': [1,2,3],\n",
    "    'randomforestclassifier__bootstrap': [False,True],\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt'],\n",
    "    'randomforestclassifier__n_estimators': [50,100,150],\n",
    "    'randomforestclassifier__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'randomforestclassifier__min_samples_leaf': [1, 2, 4],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['balanced_accuracy','recall_weighted']\n",
    "\n",
    "# Instantiate randomized search across combinations\n",
    "rnd_nm_rf = RandomizedSearchCV(estimator = clf_nm_rf, \n",
    "                                param_distributions = params_nm_rf, \n",
    "                                n_iter = 20,\n",
    "                                scoring=scores,\n",
    "                                refit='recall_weighted',\n",
    "                                error_score=0,\n",
    "                                random_state = RANDOM_STATE)\n",
    "\n",
    "# Instantiate exhaustive search across all combinations\n",
    "grd_nm_rf = GridSearchCV(estimator = clf_nm_rf, \n",
    "                          param_grid = params_nm_rf,\n",
    "                          scoring=scores,\n",
    "                          refit='recall_weighted',\n",
    "                          error_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit base pipeline\n",
    "clf_nm_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "rnd_nm_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search model\n",
    "grd_nm_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec04D\"></a>\n",
    "<h4>4D: Evaluate Tuned Classifiers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best parameters for LRCV pipeline\n",
    "grd_nm_lrcv.best_params_\n",
    "\n",
    "# Get best parameters for RF pipeline\n",
    "grd_nm_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tuned classifiers\n",
    "tuned_nm_lrcv = make_pipeline(NearMiss(),\n",
    "                               LogisticRegressionCV(random_state=RANDOM_STATE,cv=5,\n",
    "                                                    class_weight=cw_dict,\n",
    "                                                    max_iter=10000,\n",
    "                                                    scoring='recall_weighted'))\n",
    "\n",
    "tuned_nm_rf = make_pipeline(NearMiss(),\n",
    "                             RandomForestClassifier(random_state=RANDOM_STATE,\n",
    "                                                    class_weight=cw_dict,warm_start=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit tuned models\n",
    "tuned_nm_lrcv.fit(X_train,y_train)\n",
    "tuned_nm_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction with the classifier\n",
    "ypred_test_nm_lrcv = tuned_nm_lrcv.predict(X_test)\n",
    "\n",
    "# Predict class probabilities and obtain scores\n",
    "probs_nm_lrcv = tuned_nm_lrcv.predict_proba(X_test)\n",
    "probs_nm_lrcv = probs_nm_lrcv[:, 1]\n",
    "precision_nm_lrcv, recall_nm_lrcv, _ = precision_recall_curve(y_test, probs_nm_lrcv)\n",
    "f1_nm_lrcv, auc_nm_lrcv = f1_score(y_test, ypred_test_nm_lrcv), auc(recall_nm_lrcv, precision_nm_lrcv)\n",
    "\n",
    "# Make prediction with the classifier\n",
    "ypred_test_nm_rf = tuned_nm_rf.predict(X_test)\n",
    "\n",
    "# Predict class probabilities and obtain scores\n",
    "probs_nm_rf = clf_nm_rf.predict_proba(X_test)\n",
    "probs_nm_rf = probs_nm_rf[:, 1]\n",
    "precision_nm_rf, recall_nm_rf, _ = precision_recall_curve(y_test, probs_nm_rf)\n",
    "f1_nm_rf, auc_nm_rf = f1_score(y_test, ypred_test_nm_rf), auc(recall_nm_rf, precision_nm_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics for Logistic Regression classifier\n",
    "print('CLASSIFIER: LOGISTIC REGRESSION w/ NearMiss Sampling')\n",
    "print()\n",
    "\n",
    "# Compute and print key scores\n",
    "print(f\"Accuracy score:          {accuracy_score(y_test, ypred_test_nm_lrcv):.4f} (y_test, ypred_test)\")\n",
    "print(f\"Balanced accuracy score: {balanced_accuracy_score(y_test, ypred_test_nm_lrcv):.4f} (y_test, ypred_test)\")\n",
    "print(f\"Recall score:            {recall_score(y_test, ypred_test_nm_lrcv):.4f} (y_test, ypred_test)\")\n",
    "print(f\"F1 score:                {f1_nm_lrcv:.4f} (y_test, ypred_test)\")\n",
    "print(f\"AUC score:               {auc_nm_lrcv:.4f} (recall, precision)\")\n",
    "print()\n",
    "\n",
    "# Show the classification report\n",
    "print(classification_report_imbalanced(y_test, ypred_test_nm_lrcv))\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Evaluation metrics for Random Forest classifier\n",
    "print('CLASSIFIER: RANDOM FOREST w/ NearMiss Sampling')\n",
    "print()\n",
    "\n",
    "# Compute and print key scores\n",
    "print(f\"Accuracy score:          {accuracy_score(y_test, ypred_test_nm_rf):.4f} (y_test, ypred_test)\")\n",
    "print(f\"Balanced accuracy score: {balanced_accuracy_score(y_test, ypred_test_nm_rf):.4f} (y_test, ypred_test)\")\n",
    "print(f\"Recall score:            {recall_score(y_test, ypred_test_nm_rf):.4f} (y_test, ypred_test)\")\n",
    "print(f\"F1 score:                {f1_nm_rf:.4f} (y_test, ypred_test)\")\n",
    "print(f\"AUC score:               {auc_nm_rf:.4f} (recall, precision)\")\n",
    "\n",
    "# Show the classification report\n",
    "print(classification_report_imbalanced(y_test, ypred_test_nm_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix plot for test data\n",
    "y_class_names = ['Survivals','Fatalities']\n",
    "fig4D1, (ax4D1a,ax4D1b) = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "# Logistic Regression\n",
    "disp = plot_confusion_matrix(clf_nm_lr,X_test,y_test,normalize='all',\n",
    "                             ax=ax4D1a,display_labels=y_class_names,cmap='Reds')\n",
    "ax4D1a.set_title('Test Data: Logistic Regression\\nNearMiss Sampling',size=16)\n",
    "ax4D1a.set_xlabel('Predicted Label',size=14)\n",
    "ax4D1a.set_ylabel('True Label',size=14)\n",
    "\n",
    "# Random Forest\n",
    "disp = plot_confusion_matrix(clf_nm_rf,X_test,y_test,normalize='all',\n",
    "                             ax=ax4D1b,display_labels=y_class_names,cmap='Reds')\n",
    "ax4D1b.set_title('Test Data: Random Forest\\nNearMiss Sampling',size=16)\n",
    "ax4D1b.set_xlabel('Predicted Label',size=14)\n",
    "ax4D1b.set_ylabel('True Label',size=14)\n",
    "\n",
    "#plt.savefig('../graphics/CP1-04b_fig04D1.png') # Export confusion matrix plot to PNG file\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the precision-recall curves\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "fig4D2, (ax4D2a,ax4D2b) = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "# Logistic Regression\n",
    "ax4D2a.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "ax4D2a.plot(recall_nm_lr, precision_nm_lr, marker='.', label='Logistic')\n",
    "ax4D2a.set_title('Precision-Recall Curve: Logistic Regression\\nNearMiss Sampling',size=16)\n",
    "ax4D2a.set_xlabel('Recall',size=14)\n",
    "ax4D2a.set_ylabel('Precision',size=14)\n",
    "ax4D2a.legend()\n",
    "\n",
    "# Random Forest\n",
    "ax4D2b.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "ax4D2b.plot(recall_nm_rf, precision_nm_rf, marker='.', label='Random Forest')\n",
    "ax4D2b.set_title('Precision-Recall Curve: Random Forest\\nNearMiss Sampling',size=16)\n",
    "ax4D2b.set_xlabel('Recall',size=14)\n",
    "ax4D2b.set_ylabel('Precision',size=14)\n",
    "ax4D2b.legend()\n",
    "\n",
    "#plt.savefig('../graphics/CP1-04b_fig04D2.png') # Export precision-recall curves to PNG file\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-transform: uppercase;\">5. Tomek's Links (TL)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec05A\"></a>\n",
    "<h4>5A: Instantiate Training Pipelines</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pipeline for sampling method and LogisticRegressionCV (LRCV)\n",
    "clf_tl_lrcv = make_pipeline(TomekLinks(),clf_lrcv)\n",
    "\n",
    "# Make pipeline for sampling method and Random Forest (RF)\n",
    "clf_tl_rf = make_pipeline(TomekLinks(),clf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregressioncv': LogisticRegressionCV(Cs=10,\n",
      "                     class_weight={0: 0.5221381075292209,\n",
      "                                   1: 11.792744859515064},\n",
      "                     cv=None, dual=False, fit_intercept=True,\n",
      "                     intercept_scaling=1.0, l1_ratios=None, max_iter=10000,\n",
      "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                     random_state=917, refit=True, scoring='recall_weighted',\n",
      "                     solver='lbfgs', tol=0.0001, verbose=0),\n",
      " 'logisticregressioncv__Cs': 10,\n",
      " 'logisticregressioncv__class_weight': {0: 0.5221381075292209,\n",
      "                                        1: 11.792744859515064},\n",
      " 'logisticregressioncv__cv': None,\n",
      " 'logisticregressioncv__dual': False,\n",
      " 'logisticregressioncv__fit_intercept': True,\n",
      " 'logisticregressioncv__intercept_scaling': 1.0,\n",
      " 'logisticregressioncv__l1_ratios': None,\n",
      " 'logisticregressioncv__max_iter': 10000,\n",
      " 'logisticregressioncv__multi_class': 'auto',\n",
      " 'logisticregressioncv__n_jobs': None,\n",
      " 'logisticregressioncv__penalty': 'l2',\n",
      " 'logisticregressioncv__random_state': 917,\n",
      " 'logisticregressioncv__refit': True,\n",
      " 'logisticregressioncv__scoring': 'recall_weighted',\n",
      " 'logisticregressioncv__solver': 'lbfgs',\n",
      " 'logisticregressioncv__tol': 0.0001,\n",
      " 'logisticregressioncv__verbose': 0,\n",
      " 'memory': None,\n",
      " 'steps': [('tomeklinks', TomekLinks(n_jobs=None, sampling_strategy='auto')),\n",
      "           ('logisticregressioncv',\n",
      "            LogisticRegressionCV(Cs=10,\n",
      "                     class_weight={0: 0.5221381075292209,\n",
      "                                   1: 11.792744859515064},\n",
      "                     cv=None, dual=False, fit_intercept=True,\n",
      "                     intercept_scaling=1.0, l1_ratios=None, max_iter=10000,\n",
      "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                     random_state=917, refit=True, scoring='recall_weighted',\n",
      "                     solver='lbfgs', tol=0.0001, verbose=0))],\n",
      " 'tomeklinks': TomekLinks(n_jobs=None, sampling_strategy='auto'),\n",
      " 'tomeklinks__n_jobs': None,\n",
      " 'tomeklinks__sampling_strategy': 'auto',\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# Get parameters for LRCV pipeline\n",
    "pprint(clf_tl_lrcv.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None,\n",
      " 'randomforestclassifier': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                       class_weight={0: 0.5221381075292209,\n",
      "                                     1: 11.792744859515064},\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=917,\n",
      "                       verbose=0, warm_start=True),\n",
      " 'randomforestclassifier__bootstrap': True,\n",
      " 'randomforestclassifier__ccp_alpha': 0.0,\n",
      " 'randomforestclassifier__class_weight': {0: 0.5221381075292209,\n",
      "                                          1: 11.792744859515064},\n",
      " 'randomforestclassifier__criterion': 'gini',\n",
      " 'randomforestclassifier__max_depth': None,\n",
      " 'randomforestclassifier__max_features': 'auto',\n",
      " 'randomforestclassifier__max_leaf_nodes': None,\n",
      " 'randomforestclassifier__max_samples': None,\n",
      " 'randomforestclassifier__min_impurity_decrease': 0.0,\n",
      " 'randomforestclassifier__min_impurity_split': None,\n",
      " 'randomforestclassifier__min_samples_leaf': 1,\n",
      " 'randomforestclassifier__min_samples_split': 2,\n",
      " 'randomforestclassifier__min_weight_fraction_leaf': 0.0,\n",
      " 'randomforestclassifier__n_estimators': 100,\n",
      " 'randomforestclassifier__n_jobs': None,\n",
      " 'randomforestclassifier__oob_score': False,\n",
      " 'randomforestclassifier__random_state': 917,\n",
      " 'randomforestclassifier__verbose': 0,\n",
      " 'randomforestclassifier__warm_start': True,\n",
      " 'steps': [('tomeklinks', TomekLinks(n_jobs=None, sampling_strategy='auto')),\n",
      "           ('randomforestclassifier',\n",
      "            RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                       class_weight={0: 0.5221381075292209,\n",
      "                                     1: 11.792744859515064},\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=917,\n",
      "                       verbose=0, warm_start=True))],\n",
      " 'tomeklinks': TomekLinks(n_jobs=None, sampling_strategy='auto'),\n",
      " 'tomeklinks__n_jobs': None,\n",
      " 'tomeklinks__sampling_strategy': 'auto',\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# Get parameters for RF pipeline\n",
    "pprint(clf_tl_rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec05B\"></a>\n",
    "<h4>5B: Parameter Tuning - LRCV Pipeline</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter ranges for LRCV pipeline\n",
    "params_tl_lrcv ={\n",
    "    'logisticregressioncv__Cs': [1,10],\n",
    "    'logisticregressioncv__cv': [3,5],\n",
    "    'logisticregressioncv__solver': ['lbfgs','sag']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['balanced_accuracy','recall_weighted']\n",
    "\n",
    "# Instantiate randomized search across finite combinations\n",
    "rnd_tl_lrcv = RandomizedSearchCV(estimator = clf_tl_lrcv, \n",
    "                                  param_distributions = params_tl_lrcv, \n",
    "                                  n_iter = 4,\n",
    "                                  scoring=scores,\n",
    "                                  refit='recall_weighted',\n",
    "                                  error_score=0,\n",
    "                                  random_state = RANDOM_STATE)\n",
    "\n",
    "# Instantiate exhaustive search across all combinations\n",
    "grd_tl_lrcv = GridSearchCV(estimator = clf_tl_lrcv, \n",
    "                            param_grid = params_tl_lrcv,\n",
    "                            scoring=scores,\n",
    "                            refit='recall_weighted',\n",
    "                            error_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit base pipeline\n",
    "clf_tl_lrcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "rnd_tl_lrcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit the grid search model\n",
    "grd_tl_lrcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec05C\"></a>\n",
    "<h4>5C: Parameter Tuning - RF Pipeline</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter ranges for RF\n",
    "params_tl_rf ={\n",
    "    'randomforestclassifier__bootstrap': [False,True],\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt'],\n",
    "    'randomforestclassifier__n_estimators': [50,100,150],\n",
    "    'randomforestclassifier__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'randomforestclassifier__min_samples_leaf': [1, 2, 4],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['balanced_accuracy','recall_weighted']\n",
    "\n",
    "# Instantiate randomized search across combinations\n",
    "rnd_tl_rf = RandomizedSearchCV(estimator = clf_tl_rf, \n",
    "                                param_distributions = params_tl_rf, \n",
    "                                n_iter = 20,\n",
    "                                scoring=scores,\n",
    "                                refit='recall_weighted',\n",
    "                                error_score=0,\n",
    "                                random_state = RANDOM_STATE)\n",
    "\n",
    "# Instantiate exhaustive search across all combinations\n",
    "grd_tl_rf = GridSearchCV(estimator = clf_tl_rf, \n",
    "                          param_grid = params_tl_rf,\n",
    "                          scoring=scores,\n",
    "                          refit='recall_weighted',\n",
    "                          error_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit base pipeline\n",
    "clf_tl_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "rnd_tl_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search model\n",
    "grd_tl_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec05D\"></a>\n",
    "<h4>5D: Evaluate Tuned Classifiers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best parameters for LRCV pipeline\n",
    "grd_tl_lrcv.best_params_\n",
    "\n",
    "# Get best parameters for RF pipeline\n",
    "grd_tl_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tuned classifiers\n",
    "tuned_tl_lrcv = make_pipeline(TomekLinks(),\n",
    "                               LogisticRegressionCV(random_state=RANDOM_STATE,cv=5,\n",
    "                                                    class_weight=cw_dict,\n",
    "                                                    max_iter=10000,\n",
    "                                                    scoring='recall_weighted'))\n",
    "\n",
    "tuned_tl_rf = make_pipeline(TomekLinks(),\n",
    "                             RandomForestClassifier(random_state=RANDOM_STATE,\n",
    "                                                    class_weight=cw_dict,warm_start=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit tuned models\n",
    "tuned_tl_lrcv.fit(X_train,y_train)\n",
    "tuned_tl_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction with the classifier\n",
    "ypred_test_tl_lrcv = tuned_tl_lrcv.predict(X_test)\n",
    "\n",
    "# Predict class probabilities and obtain scores\n",
    "probs_tl_lrcv = tuned_tl_lrcv.predict_proba(X_test)\n",
    "probs_tl_lrcv = probs_nm_lrcv[:, 1]\n",
    "precision_tl_lrcv, recall_tl_lrcv, _ = precision_recall_curve(y_test, probs_tl_lrcv)\n",
    "f1_tl_lrcv, auc_tl_lrcv = f1_score(y_test, ypred_test_tl_lrcv), auc(recall_tl_lrcv, precision_tl_lrcv)\n",
    "\n",
    "# Make prediction with the classifier\n",
    "ypred_test_tl_rf = tuned_tl_rf.predict(X_test)\n",
    "\n",
    "# Predict class probabilities and obtain scores\n",
    "probs_tl_rf = clf_tl_rf.predict_proba(X_test)\n",
    "probs_tl_rf = probs_tl_rf[:, 1]\n",
    "precision_tl_rf, recall_tl_rf, _ = precision_recall_curve(y_test, probs_tl_rf)\n",
    "f1_tl_rf, auc_tl_rf = f1_score(y_test, ypred_test_tl_rf), auc(recall_nm_rf, precision_tl_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics for Logistic Regression classifier\n",
    "print('CLASSIFIER: LOGISTIC REGRESSION w/ Tomek\\'s Link Sampling')\n",
    "print()\n",
    "\n",
    "# Compute and print key scores\n",
    "print(f\"Accuracy score:          {accuracy_score(y_test, ypred_test_tl_lrcv):.4f} (y_test, ypred_test)\")\n",
    "print(f\"Balanced accuracy score: {balanced_accuracy_score(y_test, ypred_test_tl_lrcv):.4f} (y_test, ypred_test)\")\n",
    "print(f\"Recall score:            {recall_score(y_test, ypred_test_tl_lrcv):.4f} (y_test, ypred_test)\")\n",
    "print(f\"F1 score:                {f1_tl_lrcv:.4f} (y_test, ypred_test)\")\n",
    "print(f\"AUC score:               {auc_tl_lrcv:.4f} (recall, precision)\")\n",
    "print()\n",
    "\n",
    "# Show the classification report\n",
    "print(classification_report_imbalanced(y_test, ypred_test_tl_lrcv))\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Evaluation metrics for Random Forest classifier\n",
    "print('CLASSIFIER: RANDOM FOREST w/ Tomek\\'s Link Sampling')\n",
    "print()\n",
    "\n",
    "# Compute and print key scores\n",
    "print(f\"Accuracy score:          {accuracy_score(y_test, ypred_test_tl_rf):.4f} (y_test, ypred_test)\")\n",
    "print(f\"Balanced accuracy score: {balanced_accuracy_score(y_test, ypred_test_tl_rf):.4f} (y_test, ypred_test)\")\n",
    "print(f\"Recall score:            {recall_score(y_test, ypred_test_tl_rf):.4f} (y_test, ypred_test)\")\n",
    "print(f\"F1 score:                {f1_tl_rf:.4f} (y_test, ypred_test)\")\n",
    "print(f\"AUC score:               {auc_tl_rf:.4f} (recall, precision)\")\n",
    "\n",
    "# Show the classification report\n",
    "print(classification_report_imbalanced(y_test, ypred_test_tl_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix plot for test data\n",
    "y_class_names = ['Survivals','Fatalities']\n",
    "fig5D1, (ax5D1a,ax5D1b) = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "# Logistic Regression\n",
    "disp = plot_confusion_matrix(clf_tl_lr,X_test,y_test,normalize='all',\n",
    "                             ax=ax5D1a,display_labels=y_class_names,cmap='Reds')\n",
    "ax5D1a.set_title('Test Data: Logistic Regression\\nTomek\\'s Link Sampling',size=16)\n",
    "ax5D1a.set_xlabel('Predicted Label',size=14)\n",
    "ax5D1a.set_ylabel('True Label',size=14)\n",
    "\n",
    "# Random Forest\n",
    "disp = plot_confusion_matrix(clf_tl_rf,X_test,y_test,normalize='all',\n",
    "                             ax=ax5D1b,display_labels=y_class_names,cmap='Reds')\n",
    "ax5D1b.set_title('Test Data: Random Forest\\nTomek\\'s Link Sampling',size=16)\n",
    "ax5D1b.set_xlabel('Predicted Label',size=14)\n",
    "ax5D1b.set_ylabel('True Label',size=14)\n",
    "\n",
    "#plt.savefig('../graphics/CP1-04b_fig05D1.png') # Export confusion matrix plot to PNG file\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the precision-recall curves\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "fig5D2, (ax5D2a,ax5D2b) = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "# Logistic Regression\n",
    "ax5D2a.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "ax5D2a.plot(recall_tl_lr, precision_tl_lr, marker='.', label='Logistic')\n",
    "ax5D2a.set_title('Precision-Recall Curve: Logistic Regression\\nTomek\\'s Link Sampling',size=16)\n",
    "ax5D2a.set_xlabel('Recall',size=14)\n",
    "ax5D2a.set_ylabel('Precision',size=14)\n",
    "ax5D2a.legend()\n",
    "\n",
    "# Random Forest\n",
    "ax5D2b.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "ax5D2b.plot(recall_tl_rf, precision_tl_rf, marker='.', label='Random Forest')\n",
    "ax5D2b.set_title('Precision-Recall Curve: Random Forest\\nTomek\\'s Link Sampling',size=16)\n",
    "ax5D2b.set_xlabel('Recall',size=14)\n",
    "ax5D2b.set_ylabel('Precision',size=14)\n",
    "ax5D2b.legend()\n",
    "\n",
    "#plt.savefig('../graphics/CP1-04b_fig05D2.png') # Export precision-recall curves to PNG file\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation of Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec06A\"></a>\n",
    "<h4>6A: Comparison of Baseline Models</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to compare classifier metrics\n",
    "def eval_clf(clf, df_scores, clf_name=None):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    if clf_name is None:\n",
    "        if isinstance(clf, Pipeline):\n",
    "            clf_name = clf[-1].__class__.__name__\n",
    "        else:\n",
    "            clf_name = clf.__class__.__name__\n",
    "    acc = clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    prec_score = precision_score(y_test, y_pred) # precision score\n",
    "    rec_score = recall_score(y_test, y_pred) # recall score\n",
    "    \n",
    "    probs = clf.predict_proba(X_test)\n",
    "    probs = probs[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, probs)\n",
    "    f1, auc_val = f1_score(y_test, y_pred), auc(recall, precision) #F1 score and AUC\n",
    "   \n",
    "    clf_score = pd.DataFrame(\n",
    "        {clf_name: [acc, bal_acc, prec_score, rec_score, f1, auc_val]},\n",
    "        index=['Accuracy', 'Balanced Accuracy',\n",
    "               'Precision Score','Recall Score',\n",
    "               'F1 Score','P-R AUC']\n",
    "    )\n",
    "    df_scores = pd.concat([df_scores, clf_score], axis=1).round(decimals=4)\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dataframe to contain scores for baseline classifiers\n",
    "df_base_scores = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scores = eval_clf(clf_rus_lrcv, df_base_scores, \"LR w/ RUS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scores = eval_clf(clf_nm_lrcv, df_base_scores, \"LR w/ NearMiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scores = eval_clf(clf_tl_lrcv, df_base_scores, \"LR w/ Tomek's Links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scores = eval_clf(clf_rus_rf, df_base_scores, \"RF w/ RUS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scores = eval_clf(clf_nm_rf, df_base_scores, \"RF w/ NearMiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scores = eval_clf(clf_tl_rf, df_base_scores, \"RF w/ Tomek's Links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BASELINE CLASSIFIERS')\n",
    "df_base_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec06B\"></a>\n",
    "<h4>6B: Comparison of Tuned Models</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dataframe to contain scores for tuned classifiers\n",
    "df_tuned_scores = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuned_scores = eval_clf(tuned_rus_lrcv, df_tuned_scores, \"LR w/ RUS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuned_scores = eval_clf(tuned_nm_lrcv, df_tuned_scores, \"LR w/ NearMiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuned_scores = eval_clf(tuned_tl_lrcv, df_tuned_scores, \"LR w/ Tomek's Links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuned_scores = eval_clf(tuned_rus_rf, df_tuned_scores, \"RF w/ RUS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuned_scores = eval_clf(tuned_nm_rf, df_tuned_scores, \"RF w/ NearMiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuned_scores = eval_clf(tuned_tl_rf, df_tuned_scores, \"RF w/ Tomek's Links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TUNED CLASSIFIERS')\n",
    "df_tuned_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Sec06C\"></a>\n",
    "<h4>6C: Summary of Analyses</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#TOC>TOC</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
