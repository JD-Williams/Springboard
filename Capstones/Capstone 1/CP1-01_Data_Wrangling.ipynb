{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 1: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition: Get source data from NYC Open Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to load Batch 1 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 loaded\n",
      "Dataframe object (df1) appended to list\n",
      "\n",
      "Preparing to load Batch 2 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 loaded\n",
      "Dataframe object (df2) appended to list\n",
      "\n",
      "Preparing to load Batch 3 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3 loaded\n",
      "Dataframe object (df3) appended to list\n",
      "\n",
      "Preparing to load Batch 4 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4 loaded\n",
      "Dataframe object (df4) appended to list\n",
      "\n",
      "Preparing to load Batch 5 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5 loaded\n",
      "Dataframe object (df5) appended to list\n",
      "\n",
      "Preparing to load Batch 6 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6 loaded\n",
      "Dataframe object (df6) appended to list\n",
      "\n",
      "Preparing to load Batch 7 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7 loaded\n",
      "Dataframe object (df7) appended to list\n",
      "\n",
      "Preparing to load Batch 8 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8 loaded\n",
      "Dataframe object (df8) appended to list\n",
      "\n",
      "Preparing to load Batch 9 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9 loaded\n",
      "Dataframe object (df9) appended to list\n",
      "\n",
      "Preparing to load Batch 10 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10 loaded\n",
      "Dataframe object (df10) appended to list\n",
      "\n",
      "Preparing to load Batch 11 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11 loaded\n",
      "Dataframe object (df11) appended to list\n",
      "\n",
      "Preparing to load Batch 12 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12 loaded\n",
      "Dataframe object (df12) appended to list\n",
      "\n",
      "Preparing to load Batch 13 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13 loaded\n",
      "Dataframe object (df13) appended to list\n",
      "\n",
      "Preparing to load Batch 14 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14 loaded\n",
      "Dataframe object (df14) appended to list\n",
      "\n",
      "Preparing to load Batch 15 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15 loaded\n",
      "Dataframe object (df15) appended to list\n",
      "\n",
      "Preparing to load Batch 16 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16 loaded\n",
      "Dataframe object (df16) appended to list\n",
      "\n",
      "Preparing to load Batch 17 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17 loaded\n",
      "Dataframe object (df17) appended to list\n",
      "\n",
      "Preparing to load Batch 18 to dataframe object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18 loaded\n",
      "Dataframe object (df18) appended to list\n",
      "\n",
      "Preparing to load Batch 19 to dataframe object...\n",
      "Batch 19 loaded\n",
      "Dataframe object (df19) appended to list\n",
      "\n",
      "\n",
      "All dataframe objects have been appended to list\n"
     ]
    }
   ],
   "source": [
    "# Import Python library for Socrata Open Data API\n",
    "from sodapy import Socrata\n",
    "\n",
    "frames = []\n",
    "batch_size = 500000\n",
    "\n",
    "# Import dataset via context manager\n",
    "for i in range(18):\n",
    "    with Socrata(\"data.cityofnewyork.us\", None) as client:\n",
    "        results = client.get(\"66ae-7zpy\", limit=batch_size,offset=i*batch_size)\n",
    "    print('Preparing to load Batch {} to dataframe object...'.format(i+1))\n",
    "    temp_df = pd.DataFrame.from_records(results)\n",
    "    print('Batch {} loaded'.format(i+1))\n",
    "    frames.append(temp_df)\n",
    "    print('Dataframe object (df{}) appended to list\\n'.format(i+1))\n",
    "print('\\nAll dataframe objects have been appended to list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing: Define necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to drop immaterial rows and columns from dataframe object\n",
    "def drop_from_df(dfObj):\n",
    "    \"\"\"\n",
    "    Remove columns from dataframe object \n",
    "    that are not required for analysis\n",
    "    \"\"\"\n",
    "    # Drop all rows with missing value for 'incident_disposition_code'\n",
    "    dfObj.dropna(subset=['incident_disposition_code'],inplace=True)\n",
    "    \n",
    "    # Identify all columns that contain incident indicator data\n",
    "    list_of_indicator_cols = [name for name in list(dfObj.columns) \n",
    "                              if 'indicator' in str(name).lower() and name !='held_indicator']\n",
    "    \n",
    "    # Drop all rows that pertain to outlier incidents\n",
    "    for name in list_of_indicator_cols:\n",
    "        index_names = dfObj[dfObj[name]=='Y'].index\n",
    "        dfObj.drop(index_names, inplace=True)\n",
    "    \n",
    "    # Remove columns that contain incident indicator data\n",
    "    dfObj.drop(list_of_indicator_cols,axis=1,inplace=True)\n",
    "    \n",
    "    # Identify and remove all columns that contain district or precinct data (geographic zones)\n",
    "    list_of_zone_cols = [name for name in list(dfObj.columns) \n",
    "                         if ('district' in str(name).lower() or name=='policeprecinct')]\n",
    "    dfObj.drop(list_of_zone_cols,axis=1,inplace=True)\n",
    "    \n",
    "    return dfObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define function to modify dtypes of series in dataframe object\n",
    "def modify_dtype(dfObj):\n",
    "    \"\"\"\n",
    "    Change the dtype of select columns in \n",
    "    dataframe object based on its implied value\n",
    "    \"\"\"\n",
    "    # Create list of all columns that contain ISO8601 datetime\n",
    "    list_of_datetime_cols = [name for name in list(dfObj.columns) \n",
    "                             if 'datetime' in str(name).lower()]\n",
    "\n",
    "    # Convert dtypes for each element in list to datetime\n",
    "    for name in list_of_datetime_cols:\n",
    "        dfObj[name]=pd.to_datetime(dfObj[name],errors='coerce')\n",
    "       \n",
    "    # Create list of all columns that contain time duration\n",
    "    list_of_duration_cols = [name for name in list(dfObj.columns) \n",
    "                             if 'seconds' in str(name).lower()]\n",
    "\n",
    "    # Convert dtypes for each element in list to numeric\n",
    "    for name in list_of_duration_cols:\n",
    "        dfObj[name]=pd.to_numeric(dfObj[name],errors='coerce')\n",
    "        \n",
    "    # Convert columns to category dtypes to reduce size of dataframe object\n",
    "    dfObj['borough'] = dfObj.borough.astype('category')\n",
    "    dfObj['held_indicator'] = dfObj.held_indicator.astype('category')\n",
    "    dfObj['valid_dispatch_rspns_time_indc'] = dfObj.valid_dispatch_rspns_time_indc.astype('category')\n",
    "    dfObj['valid_incident_rspns_time_indc'] = dfObj.valid_incident_rspns_time_indc.astype('category')\n",
    "    dfObj['incident_dispatch_area'] = dfObj.incident_dispatch_area.astype('category')\n",
    "        \n",
    "    return dfObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redesign_df(dfObj):\n",
    "    \"\"\"\n",
    "    Restructure dataframe object\n",
    "    \"\"\"\n",
    "    # CREATE PANDAS SERIES FOR TARGET VARIABLE: fatality\n",
    "    dfObj['fatality'] = np.logical_or(dfObj.incident_disposition_code == '83',\\\n",
    "                                   dfObj.incident_disposition_code == '96')\n",
    "\n",
    "    # Create separate columns for the year and month of the incident\n",
    "    dfObj['incident_year'] = pd.DatetimeIndex(dfObj.incident_datetime).year\n",
    "    dfObj['incident_month'] = pd.DatetimeIndex(dfObj.incident_datetime).month\n",
    "\n",
    "    # Reorder dataframe columns\n",
    "    col_order = ['incident_year','incident_month','cad_incident_id',\\\n",
    "                 'incident_datetime','borough','zipcode',\\\n",
    "                 'incident_dispatch_area','held_indicator',\\\n",
    "                 'initial_call_type','initial_severity_level_code',\\\n",
    "                 'final_call_type','final_severity_level_code',\\\n",
    "                 'first_assignment_datetime','valid_dispatch_rspns_time_indc',\\\n",
    "                 'dispatch_response_seconds_qy','first_activation_datetime',\\\n",
    "                 'first_on_scene_datetime','valid_incident_rspns_time_indc',\\\n",
    "                 'incident_response_seconds_qy','incident_travel_tm_seconds_qy',\\\n",
    "                 'first_to_hosp_datetime','first_hosp_arrival_datetime',\\\n",
    "                 'incident_close_datetime',\n",
    "                 'incident_disposition_code','fatality']\n",
    "    dfObj=dfObj[col_order]\n",
    "    \n",
    "    # Create a multindex on incident_year and incident_month\n",
    "    dfObj.set_index(['incident_year','incident_month','cad_incident_id'])\n",
    "\n",
    "    return dfObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing: Apply functions to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe 1: Removed rows and columns\n",
      "Dataframe 2: Removed rows and columns\n",
      "Dataframe 3: Removed rows and columns\n",
      "Dataframe 4: Removed rows and columns\n",
      "Dataframe 5: Removed rows and columns\n",
      "Dataframe 6: Removed rows and columns\n",
      "Dataframe 7: Removed rows and columns\n",
      "Dataframe 8: Removed rows and columns\n",
      "Dataframe 9: Removed rows and columns\n",
      "Dataframe 10: Removed rows and columns\n",
      "Dataframe 11: Removed rows and columns\n",
      "Dataframe 12: Removed rows and columns\n",
      "Dataframe 13: Removed rows and columns\n",
      "Dataframe 14: Removed rows and columns\n",
      "Dataframe 15: Removed rows and columns\n",
      "Dataframe 16: Removed rows and columns\n",
      "Dataframe 17: Removed rows and columns\n",
      "Dataframe 18: Removed rows and columns\n"
     ]
    }
   ],
   "source": [
    "# Apply drop_from_df to all dataframe objects in frames\n",
    "count = 1\n",
    "for frame in frames:\n",
    "    frame = drop_from_df(frame)\n",
    "    print('Dataframe {}: Removed rows and columns'.format(count))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe 1: Modified dtypes\n",
      "Dataframe 2: Modified dtypes\n",
      "Dataframe 3: Modified dtypes\n",
      "Dataframe 4: Modified dtypes\n",
      "Dataframe 5: Modified dtypes\n",
      "Dataframe 6: Modified dtypes\n",
      "Dataframe 7: Modified dtypes\n",
      "Dataframe 8: Modified dtypes\n",
      "Dataframe 9: Modified dtypes\n",
      "Dataframe 10: Modified dtypes\n",
      "Dataframe 11: Modified dtypes\n",
      "Dataframe 12: Modified dtypes\n",
      "Dataframe 13: Modified dtypes\n",
      "Dataframe 14: Modified dtypes\n",
      "Dataframe 15: Modified dtypes\n",
      "Dataframe 16: Modified dtypes\n",
      "Dataframe 17: Modified dtypes\n",
      "Dataframe 18: Modified dtypes\n"
     ]
    }
   ],
   "source": [
    "# Apply modify_dtype to all dataframe objects in frames\n",
    "count = 1\n",
    "for frame in frames:\n",
    "    frame = modify_dtype(frame)\n",
    "    print(\"Dataframe {}: Modified dtypes\".format(count))\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe 1: Redesigned df object\n",
      "Dataframe 2: Redesigned df object\n",
      "Dataframe 3: Redesigned df object\n",
      "Dataframe 4: Redesigned df object\n",
      "Dataframe 5: Redesigned df object\n",
      "Dataframe 6: Redesigned df object\n",
      "Dataframe 7: Redesigned df object\n",
      "Dataframe 8: Redesigned df object\n",
      "Dataframe 9: Redesigned df object\n",
      "Dataframe 10: Redesigned df object\n",
      "Dataframe 11: Redesigned df object\n",
      "Dataframe 12: Redesigned df object\n",
      "Dataframe 13: Redesigned df object\n",
      "Dataframe 14: Redesigned df object\n",
      "Dataframe 15: Redesigned df object\n",
      "Dataframe 16: Redesigned df object\n",
      "Dataframe 17: Redesigned df object\n",
      "Dataframe 18: Redesigned df object\n"
     ]
    }
   ],
   "source": [
    "# Apply redesign_df to all dataframe objects in frames\n",
    "count = 1\n",
    "for frame in frames:\n",
    "    frame = redesign_df(frame)\n",
    "    print(\"Dataframe {}: Redesigned df object\".format(count))\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all dataframe objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated all dataframe objects in frames\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all dataframe objects\n",
    "df = pd.concat(frames,ignore_index=True)\n",
    "print('Concatenated all dataframe objects in frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_year</th>\n",
       "      <th>incident_month</th>\n",
       "      <th>cad_incident_id</th>\n",
       "      <th>incident_datetime</th>\n",
       "      <th>borough</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>incident_dispatch_area</th>\n",
       "      <th>held_indicator</th>\n",
       "      <th>initial_call_type</th>\n",
       "      <th>initial_severity_level_code</th>\n",
       "      <th>...</th>\n",
       "      <th>first_activation_datetime</th>\n",
       "      <th>first_on_scene_datetime</th>\n",
       "      <th>valid_incident_rspns_time_indc</th>\n",
       "      <th>incident_response_seconds_qy</th>\n",
       "      <th>incident_travel_tm_seconds_qy</th>\n",
       "      <th>first_to_hosp_datetime</th>\n",
       "      <th>first_hosp_arrival_datetime</th>\n",
       "      <th>incident_close_datetime</th>\n",
       "      <th>incident_disposition_code</th>\n",
       "      <th>fatality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>130010001</td>\n",
       "      <td>2013-01-01 00:00:04</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10472</td>\n",
       "      <td>B3</td>\n",
       "      <td>N</td>\n",
       "      <td>RESPIR</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-01 00:01:51</td>\n",
       "      <td>2013-01-01 00:13:21</td>\n",
       "      <td>Y</td>\n",
       "      <td>797.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>2013-01-01 00:28:49</td>\n",
       "      <td>2013-01-01 00:38:15</td>\n",
       "      <td>2013-01-01 01:04:56</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>130010002</td>\n",
       "      <td>2013-01-01 00:00:19</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10454</td>\n",
       "      <td>B1</td>\n",
       "      <td>N</td>\n",
       "      <td>CARD</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-01 00:02:08</td>\n",
       "      <td>2013-01-01 00:14:30</td>\n",
       "      <td>Y</td>\n",
       "      <td>851.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2013-01-01 00:55:34</td>\n",
       "      <td>93</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>130010004</td>\n",
       "      <td>2013-01-01 00:01:04</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11418</td>\n",
       "      <td>Q3</td>\n",
       "      <td>N</td>\n",
       "      <td>ARREST</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-01 00:01:58</td>\n",
       "      <td>2013-01-01 00:08:13</td>\n",
       "      <td>Y</td>\n",
       "      <td>429.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2013-01-01 00:38:05</td>\n",
       "      <td>83</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>130010005</td>\n",
       "      <td>2013-01-01 00:01:16</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10453</td>\n",
       "      <td>B2</td>\n",
       "      <td>N</td>\n",
       "      <td>SICK</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-01 00:02:55</td>\n",
       "      <td>2013-01-01 00:15:04</td>\n",
       "      <td>Y</td>\n",
       "      <td>828.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>2013-01-01 00:34:54</td>\n",
       "      <td>2013-01-01 00:53:02</td>\n",
       "      <td>2013-01-01 01:20:28</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>130010006</td>\n",
       "      <td>2013-01-01 00:01:26</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10457</td>\n",
       "      <td>B2</td>\n",
       "      <td>N</td>\n",
       "      <td>INJURY</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-01 00:02:55</td>\n",
       "      <td>2013-01-01 00:15:42</td>\n",
       "      <td>Y</td>\n",
       "      <td>856.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>2013-01-01 00:27:42</td>\n",
       "      <td>2013-01-01 00:31:13</td>\n",
       "      <td>2013-01-01 00:53:12</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   incident_year  incident_month cad_incident_id   incident_datetime borough  \\\n",
       "0           2013               1       130010001 2013-01-01 00:00:04   BRONX   \n",
       "1           2013               1       130010002 2013-01-01 00:00:19   BRONX   \n",
       "2           2013               1       130010004 2013-01-01 00:01:04  QUEENS   \n",
       "3           2013               1       130010005 2013-01-01 00:01:16   BRONX   \n",
       "4           2013               1       130010006 2013-01-01 00:01:26   BRONX   \n",
       "\n",
       "  zipcode incident_dispatch_area held_indicator initial_call_type  \\\n",
       "0   10472                     B3              N            RESPIR   \n",
       "1   10454                     B1              N              CARD   \n",
       "2   11418                     Q3              N            ARREST   \n",
       "3   10453                     B2              N              SICK   \n",
       "4   10457                     B2              N            INJURY   \n",
       "\n",
       "  initial_severity_level_code    ...    first_activation_datetime  \\\n",
       "0                           4    ...          2013-01-01 00:01:51   \n",
       "1                           3    ...          2013-01-01 00:02:08   \n",
       "2                           1    ...          2013-01-01 00:01:58   \n",
       "3                           6    ...          2013-01-01 00:02:55   \n",
       "4                           5    ...          2013-01-01 00:02:55   \n",
       "\n",
       "  first_on_scene_datetime valid_incident_rspns_time_indc  \\\n",
       "0     2013-01-01 00:13:21                              Y   \n",
       "1     2013-01-01 00:14:30                              Y   \n",
       "2     2013-01-01 00:08:13                              Y   \n",
       "3     2013-01-01 00:15:04                              Y   \n",
       "4     2013-01-01 00:15:42                              Y   \n",
       "\n",
       "  incident_response_seconds_qy  incident_travel_tm_seconds_qy  \\\n",
       "0                        797.0                          696.0   \n",
       "1                        851.0                          792.0   \n",
       "2                        429.0                          400.0   \n",
       "3                        828.0                          772.0   \n",
       "4                        856.0                          824.0   \n",
       "\n",
       "  first_to_hosp_datetime first_hosp_arrival_datetime incident_close_datetime  \\\n",
       "0    2013-01-01 00:28:49         2013-01-01 00:38:15     2013-01-01 01:04:56   \n",
       "1                    NaT                         NaT     2013-01-01 00:55:34   \n",
       "2                    NaT                         NaT     2013-01-01 00:38:05   \n",
       "3    2013-01-01 00:34:54         2013-01-01 00:53:02     2013-01-01 01:20:28   \n",
       "4    2013-01-01 00:27:42         2013-01-01 00:31:13     2013-01-01 00:53:12   \n",
       "\n",
       "   incident_disposition_code  fatality  \n",
       "0                         82     False  \n",
       "1                         93     False  \n",
       "2                         83      True  \n",
       "3                         82     False  \n",
       "4                         82     False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8431649, 25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8431649 entries, 0 to 8431648\n",
      "Data columns (total 25 columns):\n",
      "incident_year                     int64\n",
      "incident_month                    int64\n",
      "cad_incident_id                   object\n",
      "incident_datetime                 datetime64[ns]\n",
      "borough                           object\n",
      "zipcode                           object\n",
      "incident_dispatch_area            object\n",
      "held_indicator                    category\n",
      "initial_call_type                 object\n",
      "initial_severity_level_code       object\n",
      "final_call_type                   object\n",
      "final_severity_level_code         object\n",
      "first_assignment_datetime         datetime64[ns]\n",
      "valid_dispatch_rspns_time_indc    object\n",
      "dispatch_response_seconds_qy      int64\n",
      "first_activation_datetime         datetime64[ns]\n",
      "first_on_scene_datetime           datetime64[ns]\n",
      "valid_incident_rspns_time_indc    category\n",
      "incident_response_seconds_qy      float64\n",
      "incident_travel_tm_seconds_qy     float64\n",
      "first_to_hosp_datetime            datetime64[ns]\n",
      "first_hosp_arrival_datetime       datetime64[ns]\n",
      "incident_close_datetime           datetime64[ns]\n",
      "incident_disposition_code         object\n",
      "fatality                          bool\n",
      "dtypes: bool(1), category(2), datetime64[ns](7), float64(2), int64(3), object(10)\n",
      "memory usage: 5.7 GB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting dataframe to CSV...\n",
      "Dataframe successfully exported to CSV using 'gzip' compression.\n"
     ]
    }
   ],
   "source": [
    "# Export dataframe to CSV\n",
    "print('Exporting dataframe to CSV...')\n",
    "df.to_csv('data/clean_comp_df.csv',index=False,compression='gzip')\n",
    "print('Dataframe successfully exported to CSV using \\'gzip\\' compression.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
